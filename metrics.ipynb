{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean difference for 1-0843x4.png:  10.018514662502168\n",
      "Mean difference for 10-lena.png:  22.375782012939453\n",
      "Mean difference for 8-ADE20K-1C.png:  26.452731481481482\n",
      "Mean difference for 17-1194.png:  45.323030555555555\n",
      "Mean difference for 2-0868x4.png:  11.694742321707444\n",
      "Mean difference for 29-img_5182.png:  16.489420168067227\n",
      "Mean difference for 27-img_5264.png:  19.661710084033615\n",
      "Mean difference for 6-elephant_3.png:  8.48270034790039\n",
      "Mean difference for 24-2010_002838.png:  20.16920094562648\n",
      "Mean difference for 20-2009_003829.png:  26.78303592814371\n",
      "Mean difference for 16-P1020854.png:  21.914449869791667\n",
      "Mean difference for 25-2008_002622.png:  15.015391549295774\n",
      "Mean difference for 14-comic.png:  55.69631024930748\n",
      "Mean difference for 13-cameraman.png:  17.549687430385386\n",
      "Mean difference for 22-335094.png:  37.48322225892319\n",
      "Mean difference for 15-tire.png:  16.111541748046875\n",
      "Mean difference for 7-CITYSCAPES-2C.png:  17.355756172839506\n",
      "Mean difference for 28-img_043_SRF_2_HR.png:  36.171700613839285\n",
      "Mean difference for 30-167062.png:  10.150957571518319\n",
      "Mean difference for 4-0896x4.png:  12.153542715021112\n",
      "Mean difference for 11-NYUD-2.png:  26.096508403361344\n",
      "Mean difference for 9-MDBD-1C.png:  20.810976080246913\n",
      "Mean difference for 18-img_5935.png:  24.423361344537817\n",
      "Mean difference for 12-BIPED-1C.png:  36.14300347222222\n",
      "Mean difference for 21-00065305.png:  21.33326\n",
      "Mean difference for 3-35028.png:  16.083866037137064\n",
      "Mean difference for 19-img_6150.png:  18.62590756302521\n",
      "Mean difference for 5-WIREFRAME-2.png:  16.721855421686747\n",
      "Mean difference for 26-P1020177.png:  34.22393880208333\n",
      "Mean difference for 23-img_011_SRF_2_HR.png:  55.43455646054964\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the paths to the folders\n",
    "ground_truth_folder = '/Users/jamesdarby/Documents/McGill/COMP 551/Asg4/UDED/gt'\n",
    "result_folder = '/Users/jamesdarby/Documents/McGill/COMP 551/Asg4/TEED/result/BIPED2UDED/fused'\n",
    "\n",
    "# Get a list of filenames in the ground truth folder\n",
    "ground_truth_images = os.listdir(ground_truth_folder)\n",
    "\n",
    "# Loop through each file in the ground truth folder\n",
    "for filename in ground_truth_images:\n",
    "    if filename.endswith('.png'):\n",
    "        # Construct the full file paths\n",
    "        gt_path = os.path.join(ground_truth_folder, filename)\n",
    "        result_path = os.path.join(result_folder, filename)\n",
    "\n",
    "        # Read the images\n",
    "        gt_image = cv2.imread(gt_path, cv2.IMREAD_UNCHANGED)\n",
    "        result_image = cv2.imread(result_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        if result_image is not None:\n",
    "            # Invert the image\n",
    "            inverted_image = 255 - result_image\n",
    "\n",
    "        # Check if both images are loaded\n",
    "        if gt_image is not None and result_image is not None:\n",
    "            # Resize result image to match ground truth image if necessary\n",
    "            if gt_image.shape != result_image.shape:\n",
    "                result_image = cv2.resize(result_image, (gt_image.shape[1], gt_image.shape[0]))\n",
    "\n",
    "            inv_diff_img = cv2.absdiff(gt_image, inverted_image)\n",
    "\n",
    "            # Process the difference here (e.g., calculate statistics or save the image)\n",
    "            # For example, to save the difference image:\n",
    "            # diff_path = os.path.join('path/to/difference_folder', filename)\n",
    "            # cv2.imwrite(diff_path, difference)\n",
    "\n",
    "            # To calculate and print mean difference\n",
    "            inv_diff = np.mean(inv_diff_img)\n",
    "            print(f\"Mean difference for {filename}:  {inv_diff}\")\n",
    "\n",
    "# Add any additional processing as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def bdcn_loss2(inputs, targets, l_weight=1.1):\n",
    "    # bdcn loss modified in DexiNed\n",
    "\n",
    "    targets = targets.long()\n",
    "    mask = targets.float()\n",
    "    num_positive = torch.sum((mask > 0.0).float()).float() # >0.1\n",
    "    num_negative = torch.sum((mask <= 0.0).float()).float() # <= 0.1\n",
    "\n",
    "    mask[mask > 0.] = 1.0 * num_negative / (num_positive + num_negative) #0.1\n",
    "    mask[mask <= 0.] = 1.1 * num_positive / (num_positive + num_negative)  # before mask[mask <= 0.1]\n",
    "    inputs= torch.sigmoid(inputs)\n",
    "    cost = torch.nn.BCELoss(mask, reduction='none')(inputs, targets.float())\n",
    "    cost = torch.sum(cost.float().mean((1, 2, 3))) # before sum\n",
    "    return l_weight*cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for 1-0843x4.png: 0.04150024428963661\n",
      "Loss for 10-lena.png: 0.08813481777906418\n",
      "Loss for 8-ADE20K-1C.png: 0.11825072765350342\n",
      "Loss for 17-1194.png: 0.21944889426231384\n",
      "Loss for 2-0868x4.png: 0.06642170250415802\n",
      "Loss for 29-img_5182.png: 0.07291970402002335\n",
      "Loss for 27-img_5264.png: 0.09982876479625702\n",
      "Loss for 6-elephant_3.png: 0.032409779727458954\n",
      "Loss for 24-2010_002838.png: 0.09917829185724258\n",
      "Loss for 20-2009_003829.png: 0.14548587799072266\n",
      "Loss for 16-P1020854.png: 0.13548116385936737\n",
      "Loss for 25-2008_002622.png: 0.074457548558712\n",
      "Loss for 14-comic.png: 0.27993443608283997\n",
      "Loss for 13-cameraman.png: 0.05600902438163757\n",
      "Loss for 22-335094.png: 0.17815403640270233\n",
      "Loss for 15-tire.png: 0.07857025414705276\n",
      "Loss for 7-CITYSCAPES-2C.png: 0.08494852483272552\n",
      "Loss for 28-img_043_SRF_2_HR.png: 0.2061677873134613\n",
      "Loss for 30-167062.png: 0.035149212926626205\n",
      "Loss for 4-0896x4.png: 0.06447357684373856\n",
      "Loss for 11-NYUD-2.png: 0.12742844223976135\n",
      "Loss for 9-MDBD-1C.png: 0.06806842982769012\n",
      "Loss for 18-img_5935.png: 0.10998158901929855\n",
      "Loss for 12-BIPED-1C.png: 0.16398392617702484\n",
      "Loss for 21-00065305.png: 0.08991315215826035\n",
      "Loss for 3-35028.png: 0.085329070687294\n",
      "Loss for 19-img_6150.png: 0.08962440490722656\n",
      "Loss for 5-WIREFRAME-2.png: 0.0969429463148117\n",
      "Loss for 26-P1020177.png: 0.20303024351596832\n",
      "Loss for 23-img_011_SRF_2_HR.png: 0.32061880826950073\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loop through each file in the ground truth folder\n",
    "for filename in ground_truth_images:\n",
    "    if filename.endswith('.png'):\n",
    "        # Construct the full file paths\n",
    "        gt_path = os.path.join(ground_truth_folder, filename)\n",
    "        result_path = os.path.join(result_folder, filename)\n",
    "\n",
    "        # Read the images\n",
    "        gt_image = cv2.imread(gt_path, cv2.IMREAD_UNCHANGED).astype(np.float32) / 255.0\n",
    "        result_image = cv2.imread(result_path, cv2.IMREAD_UNCHANGED).astype(np.float32) / 255.0\n",
    "\n",
    "        # Check if both images are loaded\n",
    "        if gt_image is not None and result_image is not None:\n",
    "            # Resize result image to match ground truth image if necessary\n",
    "            if gt_image.shape != result_image.shape:\n",
    "                result_image = cv2.resize(result_image, (gt_image.shape[1], gt_image.shape[0]))\n",
    "\n",
    "            # Convert images to PyTorch tensors\n",
    "            gt_tensor = torch.tensor(gt_image).unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n",
    "            result_tensor = torch.tensor(result_image).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "            # Calculate the bdcn loss\n",
    "            loss = bdcn_loss2(result_tensor, gt_tensor)\n",
    "            print(f\"Loss for {filename}: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEED",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
